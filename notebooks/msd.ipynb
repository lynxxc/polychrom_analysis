{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gridsan/lchan/git-remotes/polychrom_analysis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2679f23effd420f9bc8b8daff76df3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import required modules\n",
    "%cd /home/gridsan/lchan/git-remotes/polychrom_analysis\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import polychrom\n",
    "from polychrom.hdf5_format import list_URIs, load_URI, load_hdf5_file\n",
    "\n",
    "from post_processing.visualization import *\n",
    "from post_processing.analysis import *\n",
    "from post_processing.compscores import *\n",
    "from post_processing.msd import *\n",
    "\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "from scipy.stats import rv_continuous\n",
    "\n",
    "import nglutils as ngu\n",
    "import nglview as nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization of polymer\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chromosomal data\n",
    "ABids = np.loadtxt(\"data/ABidentities_chr21_Su2020_2perlocus.csv\", dtype=str) # make sure to change this!\n",
    "ids = (ABids == \"A\").astype(int)\n",
    "\n",
    "# parameter sweep values\n",
    "param_set = []\n",
    "act_ratio = [1, 2, 3, 4, 5]\n",
    "e0 = [0, 0.075, 0.15, 0.225, 0.3]\n",
    "for a in act_ratio:\n",
    "    for e in e0:\n",
    "        param_set.append((a, e))\n",
    "\n",
    "simnames = [f'stickyBB_{BBenergy}_act{act_ratio}' for (act_ratio, BBenergy) in param_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite method for parameter defaults\n",
    "start_i = 1\n",
    "end_i = 2\n",
    "def extract(path, start=start_i, every_other=1, end=end_i): # put here to modify start/ends. run before previous\n",
    "    \"\"\"Extract independent snapshots from a single simulation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path to simulation directory\n",
    "    start : int\n",
    "        block number to start extracting files from\n",
    "    every_other : int\n",
    "        skip this number of blocks in between snapshots (should be large enough\n",
    "        so that snapshots are decorrelated)\n",
    "    end : int\n",
    "        last block to include in trajectory.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        confs = list_URIs(path)\n",
    "        if end:\n",
    "            uris = confs[start:end:every_other]\n",
    "        else:\n",
    "            uris = confs[start::every_other]\n",
    "    except:\n",
    "        raise Exception(\"Exception! Something went wrong\")\n",
    "        uris = []\n",
    "    return uris\n",
    "def extract_conformations(basepath, ncores=24, chain=True, **kwargs):\n",
    "    \"\"\"Extract conformations from multiple simulation replicates to be included in\n",
    "    ensemble-averaged observables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    basepath : str or Path\n",
    "        parent directory where each subdirectory is a simulation replicate for one set of parameters\n",
    "    ncores : int\n",
    "        number of cores available for parallelization\n",
    "    chain : bool\n",
    "        whether to aggregate conformations from multiple simulations into one list.\n",
    "        Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conformations : list\n",
    "        If chain is True, list of hdf5 filenames containing polymer conformations.\n",
    "        If chain is False, list of lists, where each sublist is from a separate simulation run.\n",
    "    \"\"\"\n",
    "    basepath = Path(basepath)\n",
    "    rundirs = [f for f in basepath.iterdir() if f.is_dir()]\n",
    "    runs = len(rundirs)\n",
    "    extract_func = partial(extract, **kwargs)\n",
    "    with mp.Pool(ncores) as p:\n",
    "        confs = p.map(extract_func, rundirs)\n",
    "    if chain:\n",
    "        conformations = list(itertools.chain.from_iterable(confs))\n",
    "        print(f\"Number of simulations in directory: {runs}\")\n",
    "        print(f\"Number of conformations extracted: {len(conformations)}\")\n",
    "        return conformations, runs\n",
    "    else:\n",
    "        return confs, runs\n",
    "def extract_hot_cold(simdir, D, start=100000, every_other=10):\n",
    "    \"\"\"Load conformations from a simulation trajectory stored in the hdf5 files in simdir\n",
    "    and store in two matrices, one for the `A` type monomers, and one for the `B` monomers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    simdir : str or Path\n",
    "        path to simulation directory containing .h5 files\n",
    "    D : np.ndarray\n",
    "        array of monomer diffusion coefficients.\n",
    "        Assumes there are only 2 values: D.min() and D.max().\n",
    "    start : int\n",
    "        which time block to start loading conformations from\n",
    "    every_other : int\n",
    "        skip every_other time steps when loading conformations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Xhot : array_like (num_t, N_A, 3)\n",
    "        x, y, z positions of all N_A active (hot) monomers over time\n",
    "    Xcold : array-like (num_t, N_B, 3)\n",
    "        x, y, z positions of all N_B inactive (cold) monomers over time\n",
    "\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    N = len(D)\n",
    "    data = list_URIs(simdir)\n",
    "    if start == 0:\n",
    "        starting_pos = load_hdf5_file(Path(simdir) / \"starting_conformation_0.h5\")[\n",
    "            \"pos\"\n",
    "        ]\n",
    "        X.append(starting_pos)\n",
    "    for conformation in data[start::every_other]:\n",
    "        pos = load_URI(conformation)[\"pos\"]\n",
    "        ncopies = pos.shape[0] // N\n",
    "        for i in range(ncopies):\n",
    "            posN = pos[N * i : N * (i + 1)]\n",
    "            X.append(posN)\n",
    "    X = np.array(X)\n",
    "    print(X.shape)\n",
    "    Xcold = X[:, D == D.min(), :]\n",
    "    Xhot = X[:, D == D.max(), :]\n",
    "    return Xhot, Xcold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of simulations in directory: 1\n",
      "Number of conformations extracted: 1099\n"
     ]
    }
   ],
   "source": [
    "# extract some conformations\n",
    "chromo = 'normal_logclustered'\n",
    "simname = simnames[0]\n",
    "path = f'/home/gridsan/lchan/git-remotes/polychrom_analysis/artificial_chr/{chromo}/{simname}'\n",
    "start_i = 0\n",
    "end_i = 1109\n",
    "conformations, runs = extract_conformations(path)\n",
    "np.save(f'/home/gridsan/lchan/git-remotes/polychrom_analysis/data/conformations/{chromo}/{simname}', conformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate MSDs and store as csv in data directory\n",
    "def save_MSD_time_ave(simpath, ids, savepath, every_other=11):\n",
    "    \"\"\"Compute time lag averaged MSDs averaged over active and inactive regions\n",
    "    from a single simulation trajectory in simpath. Takes ~30 min for a simulation with\n",
    "    10,000 conformations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    simpath : str or Path\n",
    "        path to simulation directory\n",
    "    ids : array-like\n",
    "        array where D==D.max() selects out A monomers and D==D.min() selects B monomers\n",
    "    savepath : str or Path\n",
    "        path to .csv file where MSDs will be saved\n",
    "    every_other : int\n",
    "        skip every_other conformation when loading conformations for MSD computation\n",
    "    \"\"\"\n",
    "    #if not Path(savepath).exists():\n",
    "    Xhot, Xcold = extract_hot_cold(Path(simpath), ids, start=1, every_other=every_other)\n",
    "    hot_msd, cold_msd = get_bead_msd_time_ave(Xhot, Xcold)\n",
    "    df_msd = pd.DataFrame()\n",
    "    df_msd[\"Times\"] = np.arange(0, len(hot_msd)) * every_other\n",
    "    df_msd[\"MSD_A\"] = hot_msd\n",
    "    df_msd[\"MSD_B\"] = cold_msd\n",
    "    df_msd.to_csv(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save MSDs to file. make sure to change directory to proper chromosome!\n",
    "simnames = ['stickyBB_0_act1'] # change this when done debug\n",
    "for simname in simnames:\n",
    "    save_MSD_time_ave(f'/home/gridsan/lchan/git-remotes/polychrom_analysis/artificial_chr/normal_logclustered/{simname}/runs1100_0_200copies', ids, \n",
    "                      f'/home/gridsan/lchan/git-remotes/polychrom_analysis/data/msds/normal_logclustered/{simname}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to plot MSDs\n",
    "def plot_msds(stickiness, act, title_append='', simname=None, ax=None):\n",
    "    if simname:\n",
    "        df = pd.read_csv(datapath/f'{simname}.csv')\n",
    "    else:\n",
    "        print('gg')\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    ax.loglog(df['Times'].values[0::20], df['MSD_A'].values[0::20], 'r-', label='A')\n",
    "    ax.loglog(df['Times'].values[0::20], df['MSD_B'].values[0::20], 'b-', label='B')\n",
    "    ax.set_xlabel('time blocks')\n",
    "    ax.set_ylabel('MSD')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'$E_BB$ = {stickiness}, $A_A / A_B$ = {act}{title_append}')\n",
    "    \n",
    "def plot_msd_panel(simpaths):\n",
    "    num_rows = 5\n",
    "    num_cols = 5\n",
    "    fig = plt.figure(figsize=(3*num_cols, 2 + 2*num_rows))\n",
    "    #extract activity / stickiness from simpath name\n",
    "    BBenergy = np.array([float(simname.split('_')[1]) for simname in simpaths])\n",
    "    activities = np.array([float(simname.split('act')[1]) for simname in simpaths])\n",
    "    if np.all(activities == activities[0]):\n",
    "        fig.suptitle(f'Mean squared displacements for activity {activities[0]}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    elif np.all(BBenergy == BBenergy[0]):\n",
    "        fig.suptitle(f'Mean squared displacements for stickiness {BBenergy[0]}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    else:\n",
    "        fig.suptitle('Mean squared displacements', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        \n",
    "    gs = GridSpec(nrows=num_rows, ncols=num_cols, \n",
    "                  width_ratios=[100]*num_cols)\n",
    "    \n",
    "    for i in range(len(simpaths)):\n",
    "        x = i // num_cols\n",
    "        y = i % num_cols\n",
    "        ax = fig.add_subplot(gs[x, y])\n",
    "        plot_msds(BBenergy[i], activities[i], simname=simpaths[i], ax=ax)\n",
    "        if np.all(activities == activities[0]):\n",
    "            ax.set_title(r'$E_{BB}=$' + f'${BBenergy[i]}kT$', fontsize=12)\n",
    "        elif np.all(BBenergy == BBenergy[0]):\n",
    "            ax.set_title(f'$A_A/A_B={activities[i]}$', fontsize=12)\n",
    "        else:\n",
    "            ax.set_title(r'$E_{BB}=$' + f'${BBenergy[i]}kT$' + f' $A_A/A_B={activities[i]}$', fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MSDs\n",
    "datapath = Path('/home/gridsan/lchan/git-remotes/polychrom_analysis/data/msds/normal_logclustered')\n",
    "plot_msds(0, 1, '', 'stickyBB_0_act1')\n",
    "simpaths = [f'stickyBB_{BBenergy}_act{act_ratio}' for (act_ratio, BBenergy) in param_set]\n",
    "#plot_msd_panel(simpaths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polyvis",
   "language": "python",
   "name": "polyvis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
